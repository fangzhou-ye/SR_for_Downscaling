{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cbba838",
   "metadata": {},
   "source": [
    "## import librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cd1056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import MSELoss\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.nn.modules.activation import ReLU, Sigmoid\n",
    "from torch.nn import Conv2d, modules\n",
    "from torch.nn import Sequential\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea15559e",
   "metadata": {},
   "source": [
    "## define SRCNN and VDSR models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04b76f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNN(nn.Module):\n",
    "    def __init__(self, num_channels=1):\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=num_channels, \n",
    "                               out_channels=64, \n",
    "                               kernel_size=9, \n",
    "                               padding=9 // 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, \n",
    "                               out_channels=32, \n",
    "                               kernel_size=5, \n",
    "                               padding=5 // 2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, \n",
    "                               out_channels=num_channels, \n",
    "                               kernel_size=5, \n",
    "                               padding=5 // 2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a7f1fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_ReLU_Block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Conv_ReLU_Block, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=64, out_channels=64,\n",
    "                              kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.conv(x))\n",
    "\n",
    "\n",
    "class VDSR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VDSR, self).__init__()\n",
    "        self.residual_layer = self.make_layer(Conv_ReLU_Block, 18)\n",
    "        self.input = nn.Conv2d(\n",
    "            in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.output = nn.Conv2d(\n",
    "            in_channels=64, out_channels=1, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, sqrt(2. / n))\n",
    "\n",
    "    def make_layer(self, block, num_of_layer):\n",
    "        layers = []\n",
    "        for _ in range(num_of_layer):\n",
    "            layers.append(block())\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.input(x))\n",
    "        out = self.residual_layer(out)\n",
    "        out = self.output(out)\n",
    "        out = torch.add(out, residual)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d46891",
   "metadata": {},
   "source": [
    "## useful functions and class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dadea504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils functions\n",
    "def img_read(fPath):\n",
    "    '''\n",
    "    read the image given path \"fPath\"\n",
    "    '''\n",
    "    img = cv2.imread(fPath, -1) # single channel image\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "def downsample(orig_img, scale):\n",
    "    '''\n",
    "    downsample by \"scale\" to get the low resolution image\n",
    "    '''\n",
    "    if scale == 1:\n",
    "        return orig_img\n",
    "    h_orig, w_orig = orig_img.shape\n",
    "    h, w = int(h_orig/scale), int(w_orig/scale)\n",
    "    return cv2.resize(orig_img, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "def bicubic_sr(lr_img, scale):\n",
    "    '''\n",
    "    bibubic super-resolved reconstruction from lr_img by factor \"scale\"\n",
    "    '''\n",
    "    h, w = lr_img.shape\n",
    "    h_orig, w_orig = h*scale, w*scale\n",
    "    return cv2.resize(lr_img, (w_orig, h_orig), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "def computePSNR(img1, img2):\n",
    "    '''\n",
    "    compute PSNR(Peak Signal to Noise Ratio) to calculate accuracy\n",
    "    img1 and img2 have range [0, 1], and both are gray level images\n",
    "    '''\n",
    "    if not img1.shape == img2.shape:\n",
    "        print(\"Input images must have the same dimensions.\")\n",
    "    mse = torch.mean((img1-img2)**2)\n",
    "    if mse == 0: # img1 and img2 are same images\n",
    "        return float('inf')\n",
    "    return 10.0 * torch.log10(1.0/mse)\n",
    "\n",
    "def getPatches(dataRoot, field):\n",
    "    '''\n",
    "    get the list of patches sorted by order\n",
    "    '''\n",
    "    dataset = os.path.join(dataRoot, field)\n",
    "    patches = []\n",
    "    for date in os.listdir(dataset):\n",
    "        dateFolder = os.path.join(dataset, date)\n",
    "        for patch in os.listdir(dateFolder):\n",
    "            patches.append(os.path.join(dateFolder, patch))\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b98ac69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRData(Dataset):\n",
    "    def __init__(self, dataRoot=\"D:\\work/dataset/\", field=\"sst\", gt_scale=1, lr_scale=9, transform=None):\n",
    "        self.dataRoot = dataRoot\n",
    "        self.field = field\n",
    "        self.gt_scale = gt_scale\n",
    "        self.lr_scale = lr_scale\n",
    "        self.transform = transform\n",
    "        self.patches = getPatches(self.dataRoot, self.field)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        orig_img = img_read(self.patches[index])# 90*90\n",
    "        gt_img = downsample(orig_img, self.gt_scale) # 90*90\n",
    "        lr_img = downsample(orig_img, self.lr_scale) #10*10\n",
    "        bicub_img = bicubic_sr(lr_img, scale=int(self.lr_scale/self.gt_scale)) # 90*90 bicubic sr\n",
    "        if self.transform:\n",
    "            gt_img = self.transform(gt_img)\n",
    "            bicub_img = self.transform(bicub_img)\n",
    "        return gt_img, bicub_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patches)\n",
    "\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec90e523",
   "metadata": {},
   "source": [
    "## prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b83f55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set length: 6400\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "prepare data\n",
    "'''\n",
    "# convert data to normalized tensor\n",
    "trans_input = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.0), (1.0)) # do nothing\n",
    "])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "     transforms.ToTensor()\n",
    "])\n",
    "\n",
    "entire_dataset = SRData(\"D:\\work/dataset\", \"sst\", \n",
    "                     gt_scale=1,\n",
    "                     lr_scale=9,\n",
    "                     transform=transform)\n",
    "\n",
    "# entire test set data\n",
    "entire_test_indices = torch.arange(57600, 64000)\n",
    "entire_test_data = torch.utils.data.Subset(entire_dataset, entire_test_indices)\n",
    "entire_test_dataloader = DataLoader(dataset=entire_test_data, batch_size=1)\n",
    "# randomly select 5 sample in test data\n",
    "sample_test_indices = np.random.randint(0, len(entire_test_indices), 5)\n",
    "sample_test_indices = [entire_test_indices[x] for x in sample_test_indices]\n",
    "sample_test_data = torch.utils.data.Subset(entire_dataset, sample_test_indices)\n",
    "sample_test_dataloader = DataLoader(dataset=sample_test_data, batch_size=1)\n",
    "print(\"test set length: {}\".format(int(len(entire_test_data))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8f798b",
   "metadata": {},
   "source": [
    "## load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9e3748e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRCNN(\n",
      "  (conv1): Conv2d(1, 64, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4))\n",
      "  (conv2): Conv2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(32, 1, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "DEVICE =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# load model\n",
    "model_srcnn = SRCNN(num_channels=1).to(DEVICE)\n",
    "\n",
    "params = torch.load(\"weights/srcnn_x9.pth\", map_location=DEVICE)\n",
    "model_srcnn.load_state_dict(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99d684bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 tested\n",
      "2000 tested\n",
      "3000 tested\n",
      "4000 tested\n",
      "5000 tested\n",
      "6000 tested\n",
      "Average PSNR bicubic and gt = 33.4954\n",
      "Average PSNR srcnn and gt = 37.6262\n"
     ]
    }
   ],
   "source": [
    "model_srcnn.to(DEVICE)\n",
    "model_srcnn.eval()\n",
    "srcnn_meter = AverageMeter()\n",
    "bicub_meter = AverageMeter()\n",
    "for data in entire_test_dataloader:\n",
    "    gt_imgs, bicub_imgs = data\n",
    "    bicub_imgs = bicub_imgs.to(DEVICE)\n",
    "    gt_imgs = gt_imgs.to(DEVICE)\n",
    "    # model prediction\n",
    "    with torch.no_grad():\n",
    "        pred_srcnn = model_srcnn(bicub_imgs).clamp(0.0, 1.0)\n",
    "    # calculate psnr\n",
    "    psnr_bicub = computePSNR(bicub_imgs, gt_imgs)\n",
    "    psnr_vdsr =  computePSNR(pred_srcnn, gt_imgs)\n",
    "    bicub_meter.update(psnr_bicub, len(gt_imgs))\n",
    "    srcnn_meter.update(psnr_vdsr, len(gt_imgs))\n",
    "    if srcnn_meter.count % 1000 == 0:\n",
    "        print(\"{} tested\".format(srcnn_meter.count))\n",
    "print(\"Average PSNR bicubic and gt = {:.4f}\".format(bicub_meter.avg))\n",
    "print(\"Average PSNR srcnn and gt = {:.4f}\".format(srcnn_meter.avg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
