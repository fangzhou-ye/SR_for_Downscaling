{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b571b7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# srcnn sst *3\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b990939",
   "metadata": {
    "id": "5b990939"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import MSELoss\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.nn.modules.activation import ReLU, Sigmoid\n",
    "from torch.nn import Conv2d, modules\n",
    "from torch.nn import Sequential\n",
    "\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8072b60d",
   "metadata": {
    "id": "40752628"
   },
   "outputs": [],
   "source": [
    "# utils functions\n",
    "def img_read(fPath):\n",
    "    '''\n",
    "    read the image given path \"fPath\"\n",
    "    '''\n",
    "    img = cv2.imread(fPath, -1) # single channel image\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "def downsample(orig_img, scale):\n",
    "    '''\n",
    "    downsample by \"scale\" to get the low resolution image\n",
    "    '''\n",
    "    if scale == 1:\n",
    "        return orig_img\n",
    "    h_orig, w_orig = orig_img.shape\n",
    "    h, w = int(h_orig/scale), int(w_orig/scale)\n",
    "    return cv2.resize(orig_img, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "def bicubic_sr(lr_img, scale):\n",
    "    '''\n",
    "    bibubic super-resolved reconstruction from lr_img by factor \"scale\"\n",
    "    '''\n",
    "    h, w = lr_img.shape\n",
    "    h_orig, w_orig = h*scale, w*scale\n",
    "    return cv2.resize(lr_img, (w_orig, h_orig), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "def computePSNR(img1, img2):\n",
    "    '''\n",
    "    compute PSNR(Peak Signal to Noise Ratio) to calculate accuracy\n",
    "    img1 and img2 have range [0, 1], and both are gray level images\n",
    "    '''\n",
    "    if not img1.shape == img2.shape:\n",
    "        print(\"Input images must have the same dimensions.\")\n",
    "    mse = torch.mean((img1-img2)**2)\n",
    "    if mse == 0: # img1 and img2 are same images\n",
    "        return float('inf')\n",
    "    return 10.0 * torch.log10(1.0/mse)\n",
    "\n",
    "def getPatches(dataRoot, field):\n",
    "    '''\n",
    "    get the list of patches sorted by order\n",
    "    '''\n",
    "    dataset = os.path.join(dataRoot, field)\n",
    "    patches = []\n",
    "    for date in os.listdir(dataset):\n",
    "        dateFolder = os.path.join(dataset, date)\n",
    "        for patch in os.listdir(dateFolder):\n",
    "            patches.append(os.path.join(dateFolder, patch))\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d78590b",
   "metadata": {
    "id": "2d78590b"
   },
   "outputs": [],
   "source": [
    "class SRCNN(nn.Module):\n",
    "    def __init__(self, num_channels=1):\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=num_channels, \n",
    "                               out_channels=64, \n",
    "                               kernel_size=9, \n",
    "                               padding=9 // 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, \n",
    "                               out_channels=32, \n",
    "                               kernel_size=5, \n",
    "                               padding=5 // 2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, \n",
    "                               out_channels=num_channels, \n",
    "                               kernel_size=5, \n",
    "                               padding=5 // 2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b8ef73",
   "metadata": {
    "id": "30b8ef73"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5770fc52",
   "metadata": {
    "id": "5770fc52"
   },
   "outputs": [],
   "source": [
    "class SRData(Dataset):\n",
    "    def __init__(self, dataRoot=\"../dataset/\", field=\"sst\", gt_scale=1, lr_scale=3, transform=None):\n",
    "        self.dataRoot = dataRoot\n",
    "        self.field = field\n",
    "        self.gt_scale = gt_scale\n",
    "        self.lr_scale = lr_scale\n",
    "        self.transform = transform\n",
    "        self.patches = getPatches(self.dataRoot, self.field)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        orig_img = img_read(self.patches[index])# 90*90\n",
    "        gt_img = downsample(orig_img, self.gt_scale) # 90*90\n",
    "        lr_img = downsample(orig_img, self.lr_scale) #30*30\n",
    "        bicub_img = bicubic_sr(lr_img, scale=int(self.lr_scale/self.gt_scale)) # 90*90 bicubic sr\n",
    "        if self.transform:\n",
    "            gt_img = self.transform(gt_img)\n",
    "            bicub_img = self.transform(bicub_img)\n",
    "        return gt_img, bicub_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1e3156",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1e1e3156",
    "outputId": "2a3946e2-55d2-4b7e-ed74-c391aa6138a4"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "hyper parameters\n",
    "'''\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if DEVICE == \"cuda\":\n",
    "    print(\"cuda available\")\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 0\n",
    "LR = 1e-4\n",
    "EPOCHS = 80\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c685050e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c685050e",
    "outputId": "7255df88-3b68-424a-e15a-e4440d5db357"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "prepare data\n",
    "'''\n",
    "# convert input to tensor\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.0), (1.0)) # do nothing\n",
    "])\n",
    "\n",
    "data = SRData(\"D:\\work/dataset\", \"sst\", \n",
    "              gt_scale=1,\n",
    "              lr_scale=3,\n",
    "              transform=trans)\n",
    "\n",
    "train_indices = torch.arange(83648)\n",
    "val_indices = torch.arange(83648, 107551)\n",
    "\n",
    "train_data = torch.utils.data.Subset(data, train_indices)\n",
    "val_data = torch.utils.data.Subset(data, val_indices)\n",
    "# data size 7 : 2 : 1\n",
    "print(\"train set length: {}\".format(int(len(train_data))))\n",
    "print(\"val set length: {}\".format(int(len(val_data))))\n",
    "# load data\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              num_workers=NUM_WORKERS,\n",
    "                              pin_memory=True,\n",
    "                              shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_data,\n",
    "                            batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21247322",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "21247322",
    "outputId": "0067b666-dc8d-4fa5-c2a6-9832e5d67eb5"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "training the SRCNN model\n",
    "'''\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "total_train_step = 0    # total training step\n",
    "total_val_step = 0      # total validation step\n",
    "\n",
    "# build model\n",
    "model = SRCNN(num_channels=1).to(DEVICE)\n",
    "# loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam([\n",
    "    {'params': model.conv1.parameters()},\n",
    "    {'params': model.conv2.parameters()},\n",
    "    {'params': model.conv3.parameters(),'lr': LR * 0.1}], lr=LR)\n",
    "# learning rate scheduler\n",
    "#scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5, verbose=True)\n",
    "# visualize (tensorboard)\n",
    "writer = SummaryWriter(\"logs\")\n",
    "\n",
    "best_weights = copy.deepcopy(model.state_dict())\n",
    "best_epoch = 0\n",
    "best_psnr = 0.0\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "count = 0\n",
    "\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    # training\n",
    "    model.train()\n",
    "    epoch_losses = AverageMeter()\n",
    "    \n",
    "    with tqdm(total=(len(train_data)), ncols=100) as t1:\n",
    "        t1.set_description('epoch train: {}/{}'.format(i+1, EPOCHS))\n",
    "        \n",
    "        for data in train_dataloader:\n",
    "            \n",
    "            # get data, transpose to device\n",
    "            gt_imgs, bicub_imgs = data\n",
    "            gt_imgs = gt_imgs.to(DEVICE)\n",
    "            bicub_imgs = bicub_imgs.to(DEVICE)\n",
    "            \n",
    "            # predict\n",
    "            predicts = model(bicub_imgs)\n",
    "            \n",
    "            # calculate loss\n",
    "            loss = loss_fn(predicts, gt_imgs)\n",
    "            epoch_losses.update(loss.item(), len(bicub_imgs))\n",
    "            \n",
    "            # optimizer\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print loss\n",
    "            t1.set_postfix(loss='{:.6f}'.format(epoch_losses.avg))\n",
    "\n",
    "            # show on tensorboard\n",
    "            total_train_step += 1            \n",
    "            if total_train_step%1000 == 0:\n",
    "            #    print(\"train step: {}，Loss: {}\".format(total_train_step, loss.item()))\n",
    "                writer.add_scalar(\"train_loss\", epoch_losses.avg, total_train_step)\n",
    "            \n",
    "            # update tqdm\n",
    "            t1.update(len(bicub_imgs))\n",
    "    \n",
    "        # scheduler\n",
    "        #scheduler.step()\n",
    "\n",
    "    # validation\n",
    "    if (i+1) % verbose == 0:\n",
    "        \n",
    "        model.eval()\n",
    "        epoch_psnr = AverageMeter()\n",
    "\n",
    "        for data in val_dataloader:\n",
    "            \n",
    "            # get data, transpose to device\n",
    "            gt_imgs, bicub_imgs = data\n",
    "            gt_imgs = gt_imgs.to(DEVICE)\n",
    "            bicub_imgs = bicub_imgs.to(DEVICE)\n",
    "            \n",
    "            # predict (no_grad) is important, not use to update model\n",
    "            # cut compute graphe to reduce needed memory of device and \n",
    "            # accelerate the computation\n",
    "            with torch.no_grad():\n",
    "                predicts = model(bicub_imgs).clamp(0.0, 1.0)\n",
    "            # calculate psnr\n",
    "            psnr =  computePSNR(predicts, gt_imgs)\n",
    "            # update total psnr\n",
    "            epoch_psnr.update(psnr, len(bicub_imgs))\n",
    "        \n",
    "        # print psnr\n",
    "        print('val set PSNR: {:.2f}'.format(epoch_psnr.avg))\n",
    "        \n",
    "        # show in tensorboard\n",
    "        total_val_step += verbose\n",
    "        writer.add_scalar(\"val_psnr\", epoch_psnr.avg, total_val_step) \n",
    "        # save best weights\n",
    "        if epoch_psnr.avg > best_psnr:\n",
    "            best_epoch = i+1\n",
    "            best_psnr = epoch_psnr.avg\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "    # save best models every 100 epochs\n",
    "    if (i+1)%20 == 0:\n",
    "        print('top {} best epoch: {}, val set psnr: {:.2f}'.format(i+1, best_epoch, best_psnr))\n",
    "        torch.save(best_weights, \"weights/top_{}_best_iter_{}.pth\".format(i+1, best_epoch))\n",
    "        print(\"best model in first {} epochs saved\".format(i+1))\n",
    "\n",
    "# close tensorboard\n",
    "writer.close()\n",
    "\n",
    "# save best model\n",
    "print('global best epoch: {}, val set psnr: {:.2f}'.format(best_epoch, best_psnr))\n",
    "torch.save(best_weights, \"weights/best_iter_{}.pth\".format(best_epoch))\n",
    "print(\"global best model saved\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "name": "trainer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
