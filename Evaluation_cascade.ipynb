{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cbba838",
   "metadata": {},
   "source": [
    "## import librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cd1056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import MSELoss\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.nn.modules.activation import ReLU, Sigmoid\n",
    "from torch.nn import Conv2d, modules\n",
    "from torch.nn import Sequential\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea15559e",
   "metadata": {},
   "source": [
    "## define SRCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04b76f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNN(nn.Module):\n",
    "    def __init__(self, num_channels=1):\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=num_channels, \n",
    "                               out_channels=64, \n",
    "                               kernel_size=9, \n",
    "                               padding=9 // 2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, \n",
    "                               out_channels=32, \n",
    "                               kernel_size=5, \n",
    "                               padding=5 // 2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, \n",
    "                               out_channels=num_channels, \n",
    "                               kernel_size=5, \n",
    "                               padding=5 // 2)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d46891",
   "metadata": {},
   "source": [
    "## useful functions and class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dadea504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils functions\n",
    "def img_read(fPath):\n",
    "    '''\n",
    "    read the image given path \"fPath\"\n",
    "    '''\n",
    "    img = cv2.imread(fPath, -1) # single channel image\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "def downsample(orig_img, scale):\n",
    "    '''\n",
    "    downsample by \"scale\" to get the low resolution image\n",
    "    '''\n",
    "    if scale == 1:\n",
    "        return orig_img\n",
    "    h_orig, w_orig = orig_img.shape\n",
    "    h, w = int(h_orig/scale), int(w_orig/scale)\n",
    "    return cv2.resize(orig_img, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "def bicubic_sr(lr_img, scale):\n",
    "    '''\n",
    "    bibubic super-resolved reconstruction from lr_img by factor \"scale\"\n",
    "    '''\n",
    "    h, w = lr_img.shape\n",
    "    h_orig, w_orig = h*scale, w*scale\n",
    "    return cv2.resize(lr_img, (w_orig, h_orig), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "def computePSNR(img1, img2):\n",
    "    '''\n",
    "    compute PSNR(Peak Signal to Noise Ratio) to calculate accuracy\n",
    "    img1 and img2 have range [0, 1], and both are gray level images\n",
    "    '''\n",
    "    if not img1.shape == img2.shape:\n",
    "        print(\"Input images must have the same dimensions.\")\n",
    "    mse = torch.mean((img1-img2)**2)\n",
    "    if mse == 0: # img1 and img2 are same images\n",
    "        return float('inf')\n",
    "    return 10.0 * torch.log10(1.0/mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b98ac69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRData(Dataset):\n",
    "    def __init__(self, dataRoot=\"D:\\work/dataset/\", field=\"sst\", inter_scale=3, lr_scale=9, transform=None):\n",
    "        self.dataRoot = dataRoot\n",
    "        self.field = field\n",
    "        self.inter_scale = inter_scale\n",
    "        self.lr_scale = lr_scale\n",
    "        self.transform = transform\n",
    "        self.patches = self.getPatches()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        T1 = img_read(self.patches[index])# 90*90\n",
    "        T3 = downsample(T1, self.inter_scale) #30*30\n",
    "        T9 = downsample(T1, self.lr_scale) # 10*10\n",
    "        bicubT9 = bicubic_sr(T9, scale=int(self.lr_scale/self.inter_scale)) # 90*90 bicubic sr\n",
    "        if self.transform:\n",
    "            T1 = self.transform(T1)\n",
    "            T3 = self.transform(T3)\n",
    "            T9 = self.transform(T9)\n",
    "            bicubT9 = self.transform(bicubT9)\n",
    "        return T1, T3, T9, bicubT9\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patches)\n",
    "\n",
    "    def getPatches(self):\n",
    "        '''\n",
    "        get the list of patches sorted by order\n",
    "        '''\n",
    "        dataset = os.path.join(self.dataRoot, self.field)\n",
    "        patches = []\n",
    "        for date in os.listdir(dataset):\n",
    "            dateFolder = os.path.join(dataset, date)\n",
    "            for patch in os.listdir(dateFolder):\n",
    "                patches.append(os.path.join(dateFolder, patch))\n",
    "        return patches\n",
    "\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec90e523",
   "metadata": {},
   "source": [
    "## prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b83f55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test set length: 6400\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "prepare data\n",
    "'''\n",
    "# convert data to normalized tensor\n",
    "trans_input = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.0), (1.0)) # do nothing\n",
    "])\n",
    "\n",
    "trans_img = transforms.ToPILImage()\n",
    "\n",
    "trans_bicub = transforms.Resize(size=90, interpolation=InterpolationMode.BICUBIC)\n",
    "\n",
    "entire_dataset = SRData(dataRoot=\"D:\\work/dataset\", field=\"sst\", inter_scale=3, lr_scale=9, transform=trans_input)\n",
    "\n",
    "# entire test set data\n",
    "entire_test_indices = torch.arange(57600, 64000)\n",
    "entire_test_data = torch.utils.data.Subset(entire_dataset, entire_test_indices)\n",
    "entire_test_dataloader = DataLoader(dataset=entire_test_data, batch_size=1)\n",
    "# randomly select 5 sample in test data\n",
    "sample_test_indices = np.random.randint(0, len(entire_test_indices), 5)\n",
    "sample_test_indices = [entire_test_indices[x] for x in sample_test_indices]\n",
    "sample_test_data = torch.utils.data.Subset(entire_dataset, sample_test_indices)\n",
    "sample_test_dataloader = DataLoader(dataset=sample_test_data, batch_size=1)\n",
    "print(\"test set length: {}\".format(int(len(entire_test_data))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8f798b",
   "metadata": {},
   "source": [
    "## Cascade Alpha = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9e3748e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# load model\n",
    "model1 = SRCNN(num_channels=1).to(DEVICE)\n",
    "model2 = SRCNN(num_channels=1).to(DEVICE)\n",
    "\n",
    "params1 = torch.load(\"weights/cascade_0.2_stage1.pth\", map_location=DEVICE)\n",
    "params2 = torch.load(\"weights/cascade_0.2_stage2.pth\", map_location=DEVICE)\n",
    "\n",
    "model1.load_state_dict(params1)\n",
    "model2.load_state_dict(params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99d684bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR cascade_0.2 and gt = 38.1243\n"
     ]
    }
   ],
   "source": [
    "model1.to(DEVICE)\n",
    "model2.to(DEVICE)\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "cascade_meter = AverageMeter()\n",
    "for data in entire_test_dataloader:\n",
    "    batch_T1, batch_T3, batch_T9, batch_bicubT9 = data\n",
    "    batch_T1 = batch_T1.to(DEVICE)\n",
    "    batch_T3 = batch_T3.to(DEVICE)\n",
    "    batch_T9 = batch_T9.to(DEVICE)\n",
    "    batch_bicubT9 = batch_bicubT9.to(DEVICE)\n",
    "    # model prediction\n",
    "    with torch.no_grad():\n",
    "        batch_I3 = model1(batch_bicubT9) # 30*30 output of model1\n",
    "        batch_bicubI3 = trans_bicub(batch_I3) # 90*90 input of model2\n",
    "        batch_I1 = model2(batch_bicubI3).clamp(0.0, 1.0)# 90*90, output of model2\n",
    "    # calculate psnr\n",
    "    psnr = computePSNR(batch_T1, batch_I1)\n",
    "    cascade_meter.update(psnr, len(batch_T1))\n",
    "print(\"Average PSNR cascade_0.2 and gt = {:.4f}\".format(cascade_meter.avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b60be0",
   "metadata": {},
   "source": [
    "## Cascade Alpha = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "416c992b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# load model\n",
    "model1 = SRCNN(num_channels=1).to(DEVICE)\n",
    "model2 = SRCNN(num_channels=1).to(DEVICE)\n",
    "\n",
    "params1 = torch.load(\"weights/cascade_0.5_stage1.pth\", map_location=DEVICE)\n",
    "params2 = torch.load(\"weights/cascade_0.5_stage2.pth\", map_location=DEVICE)\n",
    "\n",
    "model1.load_state_dict(params1)\n",
    "model2.load_state_dict(params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0438f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR cascade_0.5 and gt = 38.1089\n"
     ]
    }
   ],
   "source": [
    "model1.to(DEVICE)\n",
    "model2.to(DEVICE)\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "cascade_meter = AverageMeter()\n",
    "for data in entire_test_dataloader:\n",
    "    batch_T1, batch_T3, batch_T9, batch_bicubT9 = data\n",
    "    batch_T1 = batch_T1.to(DEVICE)\n",
    "    batch_T3 = batch_T3.to(DEVICE)\n",
    "    batch_T9 = batch_T9.to(DEVICE)\n",
    "    batch_bicubT9 = batch_bicubT9.to(DEVICE)\n",
    "    # model prediction\n",
    "    with torch.no_grad():\n",
    "        batch_I3 = model1(batch_bicubT9) # 30*30 output of model1\n",
    "        batch_bicubI3 = trans_bicub(batch_I3) # 90*90 input of model2\n",
    "        batch_I1 = model2(batch_bicubI3).clamp(0.0, 1.0)# 90*90, output of model2\n",
    "    # calculate psnr\n",
    "    psnr = computePSNR(batch_T1, batch_I1)\n",
    "    cascade_meter.update(psnr, len(batch_T1))\n",
    "print(\"Average PSNR cascade_0.5 and gt = {:.4f}\".format(cascade_meter.avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bfbf7e",
   "metadata": {},
   "source": [
    "## Cascade Alpha = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1017019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE =  \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# load model\n",
    "model1 = SRCNN(num_channels=1).to(DEVICE)\n",
    "model2 = SRCNN(num_channels=1).to(DEVICE)\n",
    "\n",
    "params1 = torch.load(\"weights/cascade_0.8_stage1.pth\", map_location=DEVICE)\n",
    "params2 = torch.load(\"weights/cascade_0.8_stage2.pth\", map_location=DEVICE)\n",
    "\n",
    "model1.load_state_dict(params1)\n",
    "model2.load_state_dict(params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d04a7534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR cascade_0.8 and gt = 37.9992\n"
     ]
    }
   ],
   "source": [
    "model1.to(DEVICE)\n",
    "model2.to(DEVICE)\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "cascade_meter = AverageMeter()\n",
    "for data in entire_test_dataloader:\n",
    "    batch_T1, batch_T3, batch_T9, batch_bicubT9 = data\n",
    "    batch_T1 = batch_T1.to(DEVICE)\n",
    "    batch_T3 = batch_T3.to(DEVICE)\n",
    "    batch_T9 = batch_T9.to(DEVICE)\n",
    "    batch_bicubT9 = batch_bicubT9.to(DEVICE)\n",
    "    # model prediction\n",
    "    with torch.no_grad():\n",
    "        batch_I3 = model1(batch_bicubT9) # 30*30 output of model1\n",
    "        batch_bicubI3 = trans_bicub(batch_I3) # 90*90 input of model2\n",
    "        batch_I1 = model2(batch_bicubI3).clamp(0.0, 1.0)# 90*90, output of model2\n",
    "    # calculate psnr\n",
    "    psnr = computePSNR(batch_T1, batch_I1)\n",
    "    cascade_meter.update(psnr, len(batch_T1))\n",
    "print(\"Average PSNR cascade_0.8 and gt = {:.4f}\".format(cascade_meter.avg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
