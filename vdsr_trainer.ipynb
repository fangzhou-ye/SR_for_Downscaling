{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b571b7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vdsr sst *3\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b990939",
   "metadata": {
    "id": "5b990939"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import MSELoss\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.nn.modules.activation import ReLU, Sigmoid\n",
    "from torch.nn import Conv2d, modules\n",
    "from torch.nn import Sequential\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13b4ae5",
   "metadata": {},
   "source": [
    "## Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8072b60d",
   "metadata": {
    "id": "40752628"
   },
   "outputs": [],
   "source": [
    "# utils functions\n",
    "def img_read(fPath):\n",
    "    '''\n",
    "    read the image given path \"fPath\"\n",
    "    '''\n",
    "    img = cv2.imread(fPath, -1) # single channel image\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "def downsample(orig_img, scale):\n",
    "    '''\n",
    "    downsample by \"scale\" to get the low resolution image\n",
    "    '''\n",
    "    if scale == 1:\n",
    "        return orig_img\n",
    "    h_orig, w_orig = orig_img.shape\n",
    "    h, w = int(h_orig/scale), int(w_orig/scale)\n",
    "    return cv2.resize(orig_img, (w, h), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "def bicubic_sr(lr_img, scale):\n",
    "    '''\n",
    "    bibubic super-resolved reconstruction from lr_img by factor \"scale\"\n",
    "    '''\n",
    "    h, w = lr_img.shape\n",
    "    h_orig, w_orig = h*scale, w*scale\n",
    "    return cv2.resize(lr_img, (w_orig, h_orig), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "def computePSNR(img1, img2):\n",
    "    '''\n",
    "    compute PSNR(Peak Signal to Noise Ratio) to calculate accuracy\n",
    "    img1 and img2 have range [0, 1], and both are gray level images\n",
    "    '''\n",
    "    if not img1.shape == img2.shape:\n",
    "        print(\"Input images must have the same dimensions.\")\n",
    "    mse = torch.mean((img1-img2)**2)\n",
    "    if mse == 0: # img1 and img2 are same images\n",
    "        return float('inf')\n",
    "    return 10.0 * torch.log10(1.0/mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3496a606",
   "metadata": {},
   "source": [
    "## Define the VDSR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d78590b",
   "metadata": {
    "id": "2d78590b"
   },
   "outputs": [],
   "source": [
    "class Conv_ReLU_Block(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Conv_ReLU_Block, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels=64, out_channels=64,\n",
    "                              kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(self.conv(x))\n",
    "\n",
    "\n",
    "class VDSR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VDSR, self).__init__()\n",
    "        self.residual_layer = self.make_layer(Conv_ReLU_Block, 18)\n",
    "        self.input = nn.Conv2d(\n",
    "            in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.output = nn.Conv2d(\n",
    "            in_channels=64, out_channels=1, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, sqrt(2. / n))\n",
    "\n",
    "    def make_layer(self, block, num_of_layer):\n",
    "        layers = []\n",
    "        for _ in range(num_of_layer):\n",
    "            layers.append(block())\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.relu(self.input(x))\n",
    "        out = self.residual_layer(out)\n",
    "        out = self.output(out)\n",
    "        out = torch.add(out, residual)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b8ef73",
   "metadata": {
    "id": "30b8ef73"
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5770fc52",
   "metadata": {
    "id": "5770fc52"
   },
   "outputs": [],
   "source": [
    "class SRData(Dataset):\n",
    "    def __init__(self, dataRoot=\"../dataset/\", field=\"sst\", gt_scale=1, lr_scale=3, transform=None):\n",
    "        self.dataRoot = dataRoot\n",
    "        self.field = field\n",
    "        self.gt_scale = gt_scale\n",
    "        self.lr_scale = lr_scale\n",
    "        self.transform = transform\n",
    "        self.patches = self.getPatches()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        orig_img = img_read(self.patches[index])# 90*90\n",
    "        gt_img = downsample(orig_img, self.gt_scale) # 90*90\n",
    "        lr_img = downsample(orig_img, self.lr_scale) #30*30\n",
    "        bicub_img = bicubic_sr(lr_img, scale=int(self.lr_scale/self.gt_scale)) # 90*90 bicubic super resolved\n",
    "        if self.transform:\n",
    "            gt_img = self.transform(gt_img)\n",
    "            bicub_img = self.transform(bicub_img)\n",
    "        return bicub_img, gt_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.patches)\n",
    "\n",
    "    def getPatches(self):\n",
    "        '''\n",
    "        get the list of patches sorted by order\n",
    "        '''\n",
    "        dataset = os.path.join(self.dataRoot, self.field)\n",
    "        patches = []\n",
    "        for date in os.listdir(dataset):\n",
    "            dateFolder = os.path.join(dataset, date)\n",
    "            for patch in os.listdir(dateFolder):\n",
    "                patches.append(os.path.join(dateFolder, patch))\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1e3156",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1e1e3156",
    "outputId": "2a3946e2-55d2-4b7e-ed74-c391aa6138a4"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "hyper parameters\n",
    "'''\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "if DEVICE == \"cuda\":\n",
    "    print(\"cuda available\")\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 0\n",
    "LR = 1e-4\n",
    "EPOCHS = 80\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c685050e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c685050e",
    "outputId": "7255df88-3b68-424a-e15a-e4440d5db357"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "prepare data\n",
    "'''\n",
    "# convert input to tensor\n",
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.0), (1.0)) # do nothing\n",
    "])\n",
    "\n",
    "data = SRData(\"D:\\work/dataset\", \"sst\", \n",
    "              gt_scale=1,\n",
    "              lr_scale=3,\n",
    "              transform=trans)\n",
    "\n",
    "train_indices = torch.arange(83648)\n",
    "val_indices = torch.arange(83648, 107551)\n",
    "\n",
    "train_data = torch.utils.data.Subset(data, train_indices)\n",
    "val_data = torch.utils.data.Subset(data, val_indices)\n",
    "# data size 7 : 2 : 1\n",
    "print(\"train set length: {}\".format(int(len(train_data))))\n",
    "print(\"val set length: {}\".format(int(len(val_data))))\n",
    "# load data\n",
    "train_dataloader = DataLoader(dataset=train_data,\n",
    "                              batch_size=BATCH_SIZE,\n",
    "                              num_workers=NUM_WORKERS,\n",
    "                              pin_memory=True,\n",
    "                              shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_data,\n",
    "                            batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdf73f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_step = 0    # total training step\n",
    "total_val_step = 0      # total validation step\n",
    "\n",
    "# build model\n",
    "model = VDSR().to(DEVICE)\n",
    "# loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "#loss_fn = loss_fn.to(DEVICE)\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR) #weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21247322",
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "21247322",
    "outputId": "0067b666-dc8d-4fa5-c2a6-9832e5d67eb5"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "training the VDSR model\n",
    "'''\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "# learning rate scheduler\n",
    "#scheduler = lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.5, verbose=True)\n",
    "# visualize (tensorboard)\n",
    "writer = SummaryWriter(\"logs\")\n",
    "\n",
    "best_weights = copy.deepcopy(model.state_dict())\n",
    "best_epoch = 0\n",
    "best_psnr = 0.0\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "count = 0\n",
    "\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    # training\n",
    "    model.train()\n",
    "    epoch_losses = AverageMeter()\n",
    "\n",
    "    #lr = adjust_learning_rate(i+1, 10)\n",
    "    #for param_group in optimizer.param_groups:\n",
    "    #    param_group[\"lr\"] = lr\n",
    "    \n",
    "    with tqdm(total=(len(train_data)), ncols=100) as t1:\n",
    "        t1.set_description('epoch train: {}/{}'.format(i+1, EPOCHS))\n",
    "        \n",
    "        for data in train_dataloader:\n",
    "            \n",
    "            # get data, transpose to device\n",
    "            lr_imgs, target_imgs = data\n",
    "            lr_imgs = lr_imgs.to(DEVICE)\n",
    "            target_imgs = target_imgs.to(DEVICE)\n",
    "            \n",
    "            # predict\n",
    "            predicts = model(lr_imgs)\n",
    "            \n",
    "            # calculate loss\n",
    "            loss = loss_fn(predicts, target_imgs)\n",
    "            epoch_losses.update(loss.item(), len(target_imgs))\n",
    "            \n",
    "            # optimizer\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            #nn.utils.clip_grad_norm_(model.parameters(), 0.4/lr)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # print loss\n",
    "            t1.set_postfix(loss='{:.6f}'.format(epoch_losses.avg))\n",
    "\n",
    "            # show on tensorboard\n",
    "            total_train_step += 1            \n",
    "            if total_train_step%1000 == 0:\n",
    "            #    print(\"train step: {}，Loss: {}\".format(total_train_step, loss.item()))\n",
    "                writer.add_scalar(\"train_loss\", epoch_losses.avg, total_train_step)\n",
    "            \n",
    "            # update tqdm\n",
    "            t1.update(len(target_imgs))\n",
    "    \n",
    "        # scheduler\n",
    "        #scheduler.step()\n",
    "\n",
    "    # validation\n",
    "    if (i+1) % verbose == 0:\n",
    "        \n",
    "        model.eval()\n",
    "        epoch_psnr = AverageMeter()\n",
    "        cubic_psnr = AverageMeter()\n",
    "\n",
    "        count=0\n",
    "\n",
    "        for data in val_dataloader:\n",
    "            \n",
    "            # get data, transpose to device\n",
    "            lr_imgs, target_imgs = data\n",
    "            lr_imgs = lr_imgs.to(DEVICE)\n",
    "            target_imgs = target_imgs.to(DEVICE)\n",
    "            \n",
    "            # predict (no_grad) is important, not use to update model\n",
    "            # cut compute graphe to reduce needed memory of device and \n",
    "            # accelerate the computation\n",
    "            with torch.no_grad():\n",
    "                predicts = model(lr_imgs).clamp(0.0, 1.0)\n",
    "            # calculate psnr\n",
    "            psnr =  computePSNR(predicts, target_imgs)\n",
    "            # update total psnr\n",
    "            epoch_psnr.update(psnr, len(target_imgs))\n",
    "\n",
    "            psnr = computePSNR(lr_imgs, target_imgs)\n",
    "            cubic_psnr.update(psnr, len(target_imgs))\n",
    "            count+=1\n",
    "        \n",
    "        # print psnr\n",
    "        print('val set PSNR: {:.4f}'.format(epoch_psnr.avg))\n",
    "        print('cubic PSNR: {:.4f}'.format(cubic_psnr.avg))\n",
    "        \n",
    "        # show in tensorboard\n",
    "        total_val_step += verbose\n",
    "        writer.add_scalar(\"val_psnr\", epoch_psnr.avg, total_val_step) \n",
    "        # save best weights\n",
    "        if epoch_psnr.avg > best_psnr:\n",
    "            best_epoch = i+1\n",
    "            best_psnr = epoch_psnr.avg\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "    # save best models every 20 epochs\n",
    "    if (i+1)%20 == 0:\n",
    "        print('top {} best epoch: {}, val set psnr: {:.4f}'.format(i+1, best_epoch, best_psnr))\n",
    "        torch.save(best_weights, \"saved_weights/top_{}_best_iter_{}.pth\".format(i+1, best_epoch))\n",
    "        print(\"best model in first {} epochs saved\".format(i+1))\n",
    "\n",
    "# close tensorboard\n",
    "writer.close()\n",
    "\n",
    "# save best model\n",
    "print('global best epoch: {}, val set psnr: {:.4f}'.format(best_epoch, best_psnr))\n",
    "torch.save(best_weights, \"saved_weights/best_vdsr_iter_{}.pth\".format(best_epoch))\n",
    "print(\"global best model saved\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "name": "trainer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
